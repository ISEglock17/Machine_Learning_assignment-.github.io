<!DOCTYPE html>
<!-- saved from url=(0087)file:///C:/Users/ISE/Desktop/shindai%20programming%20language%20I%20homework%203-2.html -->
<html lang="ja">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link rel="stylesheet" href="../notestyle.css">
    <link rel="stylesheet" href="../button.css">
    <title>自然言語処理シリーズ 1 言語処理のための機械学習入門 ノート4</title>
     <!--
    <script type="text/javascript" src="./config.js" defer></script>
    TeX: {
                equationNumbers: { autoNumber: "AMS" },
                Macros:{
                    N: "{\\mathrm{N}}",
                    dis: ["{\\displaystyle{#1}}",1],
                    bm:["{\\boldsymbol{#1}}",1],
                    dlim: ["{\\displaystyle{\\lim_{#1}}}",1],
                    ep: "{\\varepsilon}",
                    max: "{\\displaystyle{\mathrm{max}}}"
                },
                extensions: [
                    "cancel.js",           // 抹消線を有効にする。
                    "color.js"             // 文字の色付けを有効にする。
                ]
            },
    -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            TeX: {
                equationNumbers: { autoNumber: "AMS" },
                Macros:{
                    dis: ["{\\displaystyle{#1}}",1],
                    bm:["{\\boldsymbol{#1}}",1],
                    dlim: ["{\\displaystyle{\\lim_{#1}}}",1],
                    Lim: ["{\\displaystyle{\\lim_{#1 \\to \\infty}}}",1],
                    ep: "{\\varepsilon}",
                    max: "{\\mathrm{max}}",
                    N: "{\\mathbb{N}}",
                    R: "{\\mathbb{R}}",
                    min: "{\\mathrm{min}}",
                    tx: "{\\tilde{x}}",
                },
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\"] ],
                processEscapes: true
            }, 
            "HTML-CSS": {
                matchFontHeight: false,
                undefinedFamily: "Meiryo, STIXGeneral, 'Arial Unicode MS', serif",
                mtextInheritFont: true,
                scale: 100
            },
            displayAlign: "left",
            displayIndent: "4em"
        });
    </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>


<body>


    <div class="document" id="top">
        <h1><span>自然言語処理シリーズ 1 言語処理のための機械学習入門 ノート4</span></h1>
        <p style="text-align:right;">電気通信大学大学院 情報理工学研究科 情報学専攻1年 鈴木一生(2430073)</p>
        <h2>リンク集</h2>
        <div class="th" id="link">
            <span class="th-t" style="width:10em;">
                <h5>ページ構成(リンク)</h5>
            </span>
            <ul>
                <li><a href="#forth">第4章 分類</a></li>
                <ul>
                    <li><a href="#4--2">4.2.1 [2] 多変数ベルヌーイモデルのパラメータの最尤推定</a></li>
                    <li><a href="#4--3">4.2.1 [3] 多変数ベルヌーイモデルのパラメータのMAP推定</a></li>
                </ul>
                <li><a href="#shomatsu">章末問題</a></li>
                <ul>
                    <li><a href="#1">【1】</a></li>
                </ul>
                <li><a href="">教科書</a></li>
                <ul>
                    <li><a href="#4-2--2">4.2.2 [2] 多項モデルのパラメータの最尤推定</a></li>
                    <li><a href="#4-2--3">4.2.2 [3] 多項モデルのパラメータのMAP推定</a></li>
                </ul>
                <li><a href="#shomatsu2">章末問題</a></li>
                <ul>
                    <li><a href="#2">【2】</a></li>
                </ul>
                <ul>
                    <li><a href="#3">【3】</a></li>
                </ul>
                <ul>
                    <li><a href="#4">【4】</a></li>
                </ul>
                <li><a href="#rei">教科書</a></li>
                <ul>
                    <li><a href="#rei">例題4.11</a></li>
                </ul>
                <li><a href="">章末問題</a></li>
                <ul>
                    <li><a href="#5">【5】</a></li>
                </ul>
                <ul>
                    <li><a href="#6">【6】</a></li>
                </ul>
                <li><a href="">教科書</a></li>
                <ul>
                    <li><a href="#4-5-2">4.5.2 対数線形モデルの更新式の導出</a></li>
                </ul>
            </ul>
        </div>


        <h2 id="forth">第4章 分類</h2>
        <h3>教科書</h3>
        <div class="def " id="4--2">
            <span class="def-t ">
                <h4>4.2.1 [2] 多変数ベルヌーイモデルのパラメータの最尤推定</h4>
            </span>
            <p>最尤推定を用い，与えられたデータからパラメータをどのように推定するかを説明せよ。</p>
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
            <p>教科書103ページの式(4.6)に示されている，ナイーブベイズ分類器における多変数ベルヌーイモデルのパラメータにおける最尤推定であるから，
                $$\begin{align*} \log P(D) &= \sum_{(d, c) \in D} \log P(d, c) \\ &= \sum_{(d, c) \in D} \log \left(p_c \prod_{w\in V} \left(p_{w, c}^{\delta_{w, d}} (1 - p_{w, c})^{1 - \delta_{w, d}} \right) \right) \\ &=  \sum_{(d, c) \in D} \left(\log  p_c + \sum_{w\in V} \left( \delta_{w, d}\log p_{w, c} + (1 - \delta_{w, d}) \log (1 - p_{w, c}) \right) \right)\end{align*}$$
            </p>
            <p>ここで，
                $$N_{w, c}: \text{クラス$c$であり，かつ$w$を含むような訓練文書の数}$$
                $$N_{c}: \text{クラス$c$であるような訓練文書の数}$$
                と表すことにすると，$d$に関する総和を考えて，次のようになる。
            </p>
            <p>$$\log P(D) = \sum_{c} N_c \log  p_c + \sum_{c} \sum_{w\in V}  N_{w, c}\log p_{w, c} + \sum_{c} (N_c - N_{w, c}) \log (1 - p_{w, c})  $$</p>
            <p>したがって，この$\log P(D)$を制約条件$\dis{\sum_c p_c = 1}$のもとで，最大化すればよいので，ラグランジュ関数$L(p_{w, c}, \; p_c,\; \lambda)$は，
                $$L(p_{w, c}, \; p_c,\; \lambda) = \sum_{c} N_c \log  p_c + \sum_{c} \sum_{w\in V}  N_{w, c}\log p_{w, c} \\ \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad  + \sum_{c} (N_c - N_{w, c}) \log (1 - p_{w, c}) + \lambda \left(\sum_c p_c - 1 \right)$$
            </p>
            <p>よって，このラグランジュ関数$L(p_{w, c}, \; p_c,\; \lambda)$を各変数で偏微分した式それぞれが0に等しくなるような変数の値が最大値となるから，
                $$\frac{\partial L(p_{w, c}, \; p_c,\; \lambda)}{\partial p_{w, c}} = \frac{N_{w, c}}{p_{w, c}} - \frac{N_c - N_{w, c}}{1 - p_{w, c}} = 0 \cdots \cdots ①$$
                $$\frac{\partial L(p_{w, c}, \; p_c,\; \lambda)}{\partial p_{c}} = \frac{N_c}{p_c} + \lambda = 0 \cdots \cdots ➁$$
                $$\frac{\partial L(p_{w, c}, \; p_c,\; \lambda)}{\partial \lambda} = \sum_c p_c - 1 = 0 \cdots \cdots ③$$</p>
            <p>①より，$\frac{N_{w, c}}{p_{w, c}} - \frac{N_c - N_{w, c}}{1 - p_{w, c}} = 0 $に対して，両辺$p_{w, c} (1 - p_{w, c})$をかけて，
                $$N_{w, c} - N_{w, c} p_{w, c} = N_c p_{w, c} - N_{w, c} p_{w, c} $$
                $$\therefore p_{w, c} = \frac{N_{w, c}}{N_c}$$
            </p>
            <p>➁より，$p_c = - \cfrac{N_c}{\lambda}$となるから，これを③に代入して，
                $$\sum_c - \cfrac{N_c}{\lambda} = 1 \qquad \therefore \lambda = - \sum_{c} N_c$$
            </p>
            <p>よって，$p_c = \cfrac{N_c}{\dis{\sum_c} N_c}$となる。</p>
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <div class="def " id="4--3">
            <span class="def-t ">
                <h4>4.2.1 [3] 多変数ベルヌーイモデルのパラメータのMAP推定</h4>
            </span>
            <p>MAP推定を用い，与えられたデータからパラメータをどのように推定するかを説明せよ。</p>
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <h3>章末問題(p. 145)</h3>
        <div class="def " id="1">
            <span class="def-t ">
                <h4>【 1 】</h4>
            </span>
            <p>文書の長さがクラスに依存するような，多項モデルのナイーブベイズ分類器を作ってみる。文書の長さは(クラスに依存する)ポアソン分布に従うとして，$P(d|c)$を式で表せ。また，最尤推定を用いてパラメータを算出するための式を求めよ。</p>
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <h3>教科書</h3>
        <div class="def " id="4-2--2">
            <span class="def-t ">
                <h4>4.2.2 [2] 多項モデルのパラメータの最尤推定</h4>
            </span>
            
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <div class="def " id="4-2--3">
            <span class="def-t ">
                <h4>4.2.2 [3] 多項モデルのパラメータのMAP推定</h4>
            </span>
            
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <h3>章末問題</h3>
        <div class="def " id="2">
            <span class="def-t ">
                <h4>【 2 】</h4>
            </span>
           <p>多項モデルのナイーブベイズ分類器を少し変形することを考えよう。クラスが$c$であるような文書$d$において，単語$w$が$k$回出現する確率は，ポアソン分布$P(k; \mu_{w, c}) = \cfrac{\mu_{m, c}^k e^{-\mu_{m, c}}}{k!}$に従うとする。このようなモデルのナイーブベイズ分類器を作りたい。$P(d | c)$を求めよ。また，最尤推定を用いてパラメータを推定する式を求めよ。</p>
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <div class="def " id="3">
            <span class="def-t ">
                <h4>【 3 】</h4>
            </span>
            <p>SVMにおける最適化問題
                $$\min. \; \frac{1}{2} \bm{w}^2$$
                $$\mathrm{s.t. }\; y^{(i)} (\bm{w} \cdot \bm{x}^{(i)} - b) - 1 \geqq 0; \forall i$$
                は下に凸な凸計画問題であることを示せ。
            </p>
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>

        <div class="def " id="4">
            <span class="def-t ">
                <h4>【 4 】</h4>
            </span>
            <p>訓練データ$D = \{(\bm{x}^{(1)}, -1), (\bm{x}^{(2)}, 1), (\bm{x}^{(3)}, 1)\}$に対し，SVMを構築せよ。ただし，$\bm{x}^{(1)} = \left(0, \cfrac{1}{3} \right), \bm{x}^{(2)} = (1, 1), \bm{x}^{(3)} = (1, 0)$であるとする。</p>
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <h3>教科書</h3>
        <div class="def " id="rei">
            <span class="def-t ">
                <h4>例題4.11</h4>
            </span>
            <p></p>
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>

        <h3>章末問題</h3>
        <div class="def " id="5">
            <span class="def-t ">
                <h4>【 5 】</h4>
            </span>
            <p>緩和制約下のSVMについて，そのパラメータ$b$は，$0 \lt a_i \lt C$なる事例を一つ持って来て$b = \bm{w} \cdot \bm{x}^{(i)} - y^{(i)}$とすることで計算できることを示せ。KKT条件(A. 3)を用いればよい。</p>
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <div class="def " id="6">
            <span class="def-t ">
                <h4>【 6 】</h4>
            </span>
            <p>ラベル付きデータ$D^l$とラベル無しデータ$D^u$が与えられたとする。
                $$\log P(D^l)P(D^u) = \sum_{(d, c) \in D^l} \log P(d, c) + \sum_{d \in D^u} \log P(d)$$
                がデータの対数尤度である。EMアルゴリズムを用いて，これらのデータから多項モデルのナイーブベイズ分類器を構築せよ。クラス変数が隠れ変数となる($Q$関数を作る際，隠れ変数に関する期待値は$D^u$内の事例についてのみとればよい)。
            </p>
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <h3>教科書</h3>
        <div class="def " id="4-5-2">
            <span class="def-t ">
                <h4>4.5.2 対数線形モデルの更新式の導出</h4>
            </span>
            
        </div>

        <div class="ans">
            <span class="ans-t">
                <h5>解答</h5>
            </span>
           
        </div>
        <p style="text-align:right;"><a href="#top" class="btn-square-slant ">↑トップに戻る</a></p>

        <div class="flex">
            <p style="width:33%;"><a href="./note3.html " class="btn-square-slant ">←前のページに移る</a></p>
            <p style="width:33%;"><a href="../index.html " class="btn-square-slant ">トップページに戻る</a></p>
            <p style="width:33%;"><a href="./note5.html " class="btn-square-slant ">次のページに移る→</a></p>
        </div>

        <br>

</body>

</html>